{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3590b50b-5fc3-4cdc-a9ca-97f9bd2ccdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calculation(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates the following values (TP, FP, TN, FN).\n",
    "    It takes in y_true (which are actual class labels) and y_pred (which are predicted class labels)\n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i]==y_pred[i]==1:\n",
    "            TP+=1\n",
    "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
    "            FP+=1\n",
    "        if y_true[i]==y_pred[i]==0:\n",
    "            TN+=1\n",
    "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
    "            FN+=1\n",
    "    return (TP, FP, TN, FN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259e71b6-3661-4c07-ae47-1d8835439f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True Class labels are [1, 0, 1, 0, 0, 1]\n",
      "The Predicted Class labels are [0, 0, 1, 1, 0, 1]\n",
      "The number of True Positives are 2\n",
      "The number of False Positives are 1\n",
      "The number of True Negatives are 2\n",
      "The number of False Negatives are 1\n"
     ]
    }
   ],
   "source": [
    "y_true = [1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0, 0, 1, 1, 0, 1]\n",
    "TP, FP, TN, FN = confusion_matrix_calculation(y_true, y_pred)\n",
    "print(f\"The True Class labels are {y_true}\")\n",
    "print(f\"The Predicted Class labels are {y_pred}\")\n",
    "print(f\"The number of True Positives are {TP}\")\n",
    "print(f\"The number of False Positives are {FP}\")\n",
    "print(f\"The number of True Negatives are {TN}\")\n",
    "print(f\"The number of False Negatives are {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f49015d-63de-42de-978a-f51d5632e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [0, 2,  1, 3]\n",
    "y_pred = [0, 1, 2, 3]\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c140fffb-10af-4c11-bebc-4a7cc63a727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.67      1.00      0.80         2\n",
      "     class_1       0.00      0.00      0.00         1\n",
      "     class_2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.56      0.50      0.49         5\n",
      "weighted avg       0.67      0.60      0.59         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 0]\n",
    "y_pred = [0, 0, 2, 1, 0]\n",
    "target_names = [\"class_0\", \"class_1\", 'class_2']\n",
    "print(classification_report(y_true, y_pred, target_names = target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
